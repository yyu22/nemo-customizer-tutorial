{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba95e45e",
   "metadata": {},
   "source": [
    "# Customizing Llama-3.3-Nemotron-Super-49B-v1.5 with Nemo Customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad0729-7f75-464d-95e4-077726af16cc",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to easily fine-tune the Llama-3.3-Nemotron-Super-49B-v1.5 model using NeMo Customizer. It provides a minimal, end-to-end example that highlights how simple and streamlined the customization process is—from setup to fine-tuning and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcafaea-fcb4-45ff-9242-5309bc50796b",
   "metadata": {},
   "source": [
    "## Step 0. Install Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344436f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NGC API Key ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['NGC_API_KEY'] = getpass(\"Enter your NGC API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a6cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Huggingface token ········\n"
     ]
    }
   ],
   "source": [
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = getpass(\"Enter your Huggingface token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3207aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO]\u001b[0m Starting NeMo Microservices deployment...\n",
      "\u001b[1;32m[INFO]\u001b[0m Detailed logs will be written to: /tmp/nemo-deploy.log\n",
      "\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 1/8: Checking prerequisites [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 12%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 2/8: Downloading Helm chart [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 3/8: Starting Minikube [██████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 37%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 4/8: Setting up NGC and Helm [█████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 50%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 5/8: Installing NeMo microservices [███████████████████████████████░░░░░░░░░░░░░░░░░░░] 62%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 6/8: Waiting for pods [█████████████████████████████████████░░░░░░░░░░░░░] 75%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 7/8: Checking pod health [███████████████████████████████████████████░░░░░░░] 87%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 8/8: Configuring DNS [██████████████████████████████████████████████████] 100%\n",
      "\u001b[1;32m[INFO]\u001b[0m Deployment completed successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x ./deploy-nmp-2510_nemotron.sh\n",
    "./deploy-nmp-2510_nemotron.sh --progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af180650-9837-4d12-9c3a-e64b79d9e33e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /tmp/tmp7ur17iwq\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.0.1)\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (80.9.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.2 wheel-0.45.1\n",
      "/home/ubuntu/.venv/bin/pip\n",
      "Collecting nemo-microservices==1.1.0\n",
      "  Using cached nemo_microservices-1.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting huggingface-hub==0.34.4\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from nemo-microservices==1.1.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (0.28.1)\n",
      "Collecting pydantic<3,>=1.9.0 (from nemo-microservices==1.1.0)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (4.15.0)\n",
      "Collecting filelock (from huggingface-hub==0.34.4)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub==0.34.4)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface-hub==0.34.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub==0.34.4) (6.0.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub==0.34.4) (2.32.5)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub==0.34.4)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub==0.34.4)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->nemo-microservices==1.1.0) (3.11)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->nemo-microservices==1.1.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->nemo-microservices==1.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->nemo-microservices==1.1.0) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->nemo-microservices==1.1.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->nemo-microservices==1.1.0)\n",
      "  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->nemo-microservices==1.1.0)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub==0.34.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub==0.34.4) (2.5.0)\n",
      "Using cached nemo_microservices-1.1.0-py3-none-any.whl (750 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, pydantic-core, hf-xet, fsspec, filelock, distro, annotated-types, pydantic, huggingface-hub, nemo-microservices\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [nemo-microservices]emo-microservices]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 filelock-3.20.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.34.4 nemo-microservices-1.1.0 pydantic-2.12.3 pydantic-core-2.41.4 tqdm-4.67.1 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source .venv/bin/activate\n",
    "python -m ensurepip --upgrade\n",
    "python -m pip install --upgrade pip setuptools wheel\n",
    "pip install nemo-microservices==1.1.0 huggingface-hub==0.34.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec26957",
   "metadata": {},
   "source": [
    "## Step 1. Initilize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73ff219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices import NeMoMicroservices\n",
    "\n",
    "# Configure microservice host URLs\n",
    "NEMO_BASE_URL = \"http://nemo.test\"\n",
    "NIM_BASE_URL = \"http://nim.test\"\n",
    "DATA_STORE_BASE_URL = \"http://data-store.test\"\n",
    "\n",
    "# Initialize the client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_BASE_URL,\n",
    "    inference_base_url=NIM_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82cf0f",
   "metadata": {},
   "source": [
    "## Step 2. Upload and Register Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6539fa6f-10b9-4679-b9c9-94de4fca5d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "training.jsonl: 100%|██████████| 633k/633k [00:00<00:00, 66.8MB/s]\n",
      "validation.jsonl: 100%|██████████| 77.5k/77.5k [00:00<00:00, 10.9MB/s]\n",
      "testing.jsonl: 100%|██████████| 82.6k/82.6k [00:00<00:00, 16.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload testing/testing.jsonl with huggingface_hub', commit_description='', oid='fe943486843c86e9077f6e6a9049d72d18734779', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, upload_file\n",
    "\n",
    "# Define entity details\n",
    "NAMESPACE = \"nemotron-tutorial\"\n",
    "DATASET_NAME = \"example-dataset\"\n",
    "\n",
    "# Initialize HF API client\n",
    "hf_api = HfApi(endpoint=f\"{DATA_STORE_BASE_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create dataset repo in datastore\n",
    "repo_id = f\"{NAMESPACE}/{DATASET_NAME}\"\n",
    "hf_api.create_repo(repo_id , repo_type=\"dataset\")\n",
    "\n",
    "# Upload the dataset\n",
    "hf_api.upload_file(\n",
    "      repo_type=\"dataset\",\n",
    "      repo_id=repo_id,\n",
    "      revision=\"main\",\n",
    "      path_or_fileobj=\"./dataset/training.jsonl\",\n",
    "      path_in_repo=\"training/training.jsonl\" \n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "      repo_type=\"dataset\",\n",
    "      repo_id=repo_id,\n",
    "      revision=\"main\",\n",
    "      path_or_fileobj=\"./dataset/validation.jsonl\",\n",
    "      path_in_repo=\"validation/validation.jsonl\" \n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "      repo_type=\"dataset\",\n",
    "      repo_id=repo_id,\n",
    "      revision=\"main\",\n",
    "      path_or_fileobj=\"./dataset/testing.jsonl\",\n",
    "      path_in_repo=\"testing/testing.jsonl\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f837cc2d-5bde-48e0-94a5-82f5acfd6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(files_url='hf://datasets/nemotron-tutorial/example-dataset', id='dataset-GmW7sSZDkaNUjKMAvE9Hqx', created_at=datetime.datetime(2025, 10, 22, 0, 21, 2, 168799), custom_fields={}, description='test dataset', format=None, hf_endpoint=None, limit=None, name='example-dataset', namespace='nemotron-tutorial', project='customizer-tutorial', split=None, updated_at=datetime.datetime(2025, 10, 22, 0, 21, 2, 168802))\n"
     ]
    }
   ],
   "source": [
    "# Register Dataset in NeMo Entity Store\n",
    "response = nemo_client.datasets.create(\n",
    "    name=DATASET_NAME,\n",
    "    namespace=NAMESPACE,\n",
    "    description=\"test dataset\",\n",
    "    files_url=f\"hf://datasets/{NAMESPACE}/{DATASET_NAME}\",\n",
    "    project=\"customizer-tutorial\",\n",
    "    custom_fields={},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a141e34-3d83-4215-bece-d795e9c65dc6",
   "metadata": {},
   "source": [
    "## Step 3. Run Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad28915-fc22-4d1a-b33e-e2b5e2d68d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 targets\n",
      "Target: nemotron-super-llama-3.3-49b@1.5 - Status: ready\n"
     ]
    }
   ],
   "source": [
    "# Confirm model target is ready\n",
    "targets = nemo_client.customization.targets.list(\n",
    "    page=1,\n",
    "    page_size=10,\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "print(f\"Found {len(targets.data)} targets\")\n",
    "for target in targets.data:\n",
    "    print(f\"Target: {target.name} - Status: {target.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffc06fbf-161e-4532-9c54-d05c3b6d6bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 configurations\n",
      "Config namespace: nvidia\n",
      "Config name: nemotron-super-llama-3.3-49b@v1.5+A100\n",
      "  Training options: 1\n",
      "    - sft/lora: 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "# Confirm customization configuration is available\n",
    "configs = nemo_client.customization.configs.list()\n",
    "\n",
    "print(f\"Found {len(configs.data)} configurations\")\n",
    "for config in configs.data:\n",
    "    print(f\"Config namespace: {config.namespace}\")\n",
    "    print(f\"Config name: {config.name}\")\n",
    "    print(f\"  Training options: {len(config.training_options)}\")\n",
    "    for option in config.training_options:\n",
    "        print(f\"    - {option.training_type}/{option.finetuning_type}: {option.num_gpus} GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cfb602-2508-4f2d-8cb4-7f1dadaed52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomizationConfig(max_seq_length=4096, training_options=[CustomizationTrainingOption(finetuning_type='lora', micro_batch_size=1, num_gpus=4, training_type='sft', data_parallel_size=1, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=4, use_sequence_parallel=False)], chat_prompt_template=None, created_at=datetime.datetime(2025, 10, 21, 23, 18, 5, 333897), dataset_schemas=[{'$schema': 'https://json-schema.org/draft/2020-12/schema', '$id': 'https://nemo.nvidia.com/schema.json', 'title': 'Nemo Style Conversation Chat Dataset - SFT Training Type - Newline-Delimited JSON File', 'description': '\\n                Newline-delimited JSON (application/jsonlines) file containing Nemo Style Conversation Chat Dataset - SFT Training Type objects.\\n                This is represented as an array here, however data should be newline separated instead of a list.', '$defs': {'Message': {'description': 'Represents a single message in a chat conversation.', 'properties': {'from': {'description': 'The role of the user attributed to this message', 'title': 'From', 'type': 'string'}, 'value': {'description': 'The content of the message attributed to this user', 'title': 'Value', 'type': 'string'}, 'label': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'An optional label to add to the message before or after the content, depending on type', 'title': 'Label'}}, 'required': ['from', 'value'], 'title': 'Message', 'type': 'object'}, 'SourceTypeEnum': {'description': 'Enumeration of source types for chat dataset formatting.\\n\\nDefines how labels should be formatted in chat conversations:\\n- VALUE_TO_TEXT: Label appears before the text\\n- TEXT_TO_VALUE: Label appears after the text', 'enum': ['VALUE_TO_TEXT', 'TEXT_TO_VALUE'], 'title': 'SourceTypeEnum', 'type': 'string'}}, 'type': 'array', 'items': {'description': 'Schema for chat-based training data items.\\n\\nDefines the structure for multi-turn conversations used in training.', 'properties': {'system': {'default': '', 'description': 'The system message to apply to the conversation', 'title': 'System', 'type': 'string'}, 'system_role': {'default': 'System', 'description': 'The role of the system user', 'title': 'System Role', 'type': 'string'}, 'system_label': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': '', 'description': 'A label to include with the system message', 'title': 'System Label'}, 'mask': {'default': 'User', 'description': 'The role that will be masked from the model during training. This should match roles in your conversations', 'title': 'Mask', 'type': 'string'}, 'type': {'anyOf': [{'$ref': '#/$defs/SourceTypeEnum'}, {'type': 'null'}], 'default': None, 'description': 'One of VALUE_TO_TEXT, TEXT_TO_VALUE, or None. VALUE_TO_TEXT will put the label (if included) inside the turn, before the text of the user.TEXT_TO_VALUE will put the label (if included) after the turn for the user.'}, 'conversations': {'description': 'A list of messages that will be formatted', 'items': {'$ref': '#/$defs/Message'}, 'title': 'Conversations', 'type': 'array'}}, 'required': ['conversations'], 'title': 'ChatDatasetItemSchema', 'type': 'object'}}, {'$schema': 'https://json-schema.org/draft/2020-12/schema', '$id': 'https://nemo.nvidia.com/schema.json', 'title': 'OpenAI Style Chat Dataset - SFT Training Type - Newline-Delimited JSON File', 'description': '\\n                Newline-delimited JSON (application/jsonlines) file containing OpenAI Style Chat Dataset - SFT Training Type objects.\\n                This is represented as an array here, however data should be newline separated instead of a list.', '$defs': {'FunctionCall': {'properties': {'name': {'description': 'Name of the function to call.', 'title': 'Name', 'type': 'string'}, 'content_type': {'default': 'json', 'description': 'The content type of the tool call, defaults to json', 'title': 'Content Type', 'type': 'string'}, 'arguments': {'description': 'Arguments for the function as a JSON object.', 'title': 'Arguments', 'type': 'object'}}, 'required': ['name', 'arguments'], 'title': 'FunctionCall', 'type': 'object'}, 'FunctionParameter': {'additionalProperties': True, 'properties': {'type': {'description': 'The type of the parameter provided.', 'title': 'Type', 'type': 'string'}, 'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'The description of this parameter.', 'title': 'Description'}}, 'required': ['type'], 'title': 'FunctionParameter', 'type': 'object'}, 'FunctionParameters': {'additionalProperties': True, 'properties': {'type': {'const': 'object', 'default': 'object', 'description': \"Type of parameters - currently only 'object' is supported.\", 'title': 'Type', 'type': 'string'}, 'properties': {'anyOf': [{'additionalProperties': {'$ref': '#/$defs/FunctionParameter'}, 'type': 'object'}, {'type': 'null'}], 'default': None, 'description': 'Dictionary of parameter names to their type definitions.', 'title': 'Properties'}, 'required': {'description': 'List of required parameter names.', 'items': {'type': 'string'}, 'title': 'Required', 'type': 'array'}, 'additionalProperties': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': True, 'description': 'Additional properties are allowed.', 'title': 'Additionalproperties'}}, 'title': 'FunctionParameters', 'type': 'object'}, 'FunctionSchema': {'additionalProperties': False, 'properties': {'name': {'description': 'Name of the function.', 'title': 'Name', 'type': 'string'}, 'description': {'description': 'Description of what the function does.', 'title': 'Description', 'type': 'string'}, 'parameters': {'$ref': '#/$defs/FunctionParameters', 'description': 'Parameters schema for the function.'}, 'required': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Required parameters for the function', 'title': 'Required'}, 'strict': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Whether the verification is in strict mode.', 'title': 'Strict'}}, 'required': ['name', 'description', 'parameters'], 'title': 'FunctionSchema', 'type': 'object'}, 'HFMessage': {'anyOf': [{'not': {'required': ['thinking']}, 'properties': {'content': {'type': 'string'}}, 'required': ['content']}, {'not': {'required': ['content']}, 'properties': {'thinking': {'type': 'string'}}, 'required': ['thinking']}, {'properties': {'tool_calls': {'minItems': 1}}, 'required': ['tool_calls']}], 'properties': {'role': {'title': 'Role', 'type': 'string'}, 'content': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Content'}, 'thinking': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Thinking'}, 'tool_calls': {'anyOf': [{'items': {'$ref': '#/$defs/ToolCall'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'title': 'Tool Calls'}}, 'required': ['role'], 'title': 'HFMessage', 'type': 'object'}, 'ToolCall': {'properties': {'type': {'const': 'function', 'description': \"Type of tool call. Must be 'function'.\", 'title': 'Type', 'type': 'string'}, 'function': {'$ref': '#/$defs/FunctionCall', 'description': 'Function call details.'}}, 'required': ['type', 'function'], 'title': 'ToolCall', 'type': 'object'}, 'ToolSchema': {'additionalProperties': False, 'properties': {'type': {'const': 'function', 'default': 'function', 'description': \"Type of tool - currently only 'function' is supported\", 'title': 'Type', 'type': 'string'}, 'function': {'$ref': '#/$defs/FunctionSchema', 'description': 'Schema defining the function'}}, 'required': ['function'], 'title': 'ToolSchema', 'type': 'object'}}, 'type': 'array', 'items': {'description': 'Schema for chat-based training data items.\\n\\nDefines the structure for multi-turn conversations used in training using HF OpenAI.', 'properties': {'messages': {'description': 'A list of messages that will be formatted', 'items': {'$ref': '#/$defs/HFMessage'}, 'title': 'Messages', 'type': 'array'}, 'tools': {'anyOf': [{'items': {'$ref': '#/$defs/ToolSchema'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'A list of tools available for use during this conversation', 'title': 'Tools'}}, 'required': ['messages'], 'title': 'HFChatDatasetItemSchema', 'type': 'object'}}, {'$schema': 'https://json-schema.org/draft/2020-12/schema', '$id': 'https://nemo.nvidia.com/schema.json', 'title': 'Simple Prompt Completion Dataset - SFT Training Type - Newline-Delimited JSON File', 'description': '\\n                Newline-delimited JSON (application/jsonlines) file containing Simple Prompt Completion Dataset - SFT Training Type objects.\\n                This is represented as an array here, however data should be newline separated instead of a list.', '$defs': {}, 'type': 'array', 'items': {'properties': {'prompt': {'description': 'The prompt for the entry - context used for training', 'title': 'Prompt', 'type': 'string'}, 'completion': {'description': 'The completion - the completion that the model should learn', 'title': 'Completion', 'type': 'string'}}, 'required': ['prompt', 'completion'], 'title': 'SFTDatasetItemSchema', 'type': 'object'}}], description=None, name='nemotron-super-llama-3.3-49b@v1.5+A100', namespace='nvidia', ownership=None, pod_spec=None, project=None, prompt_template='{prompt} {completion}', target=CustomizationTarget(model_path='nemotron-super-3_3-49b_v1_5', num_parameters=4900000000, precision='bf16-mixed', id='cust-target-VJotFMjw5REnFxdSBmz9Hz', base_model='nvidia/nemotron-super-llama-3.3-49b-v1.5', created_at=datetime.datetime(2025, 10, 21, 23, 18, 5, 122679), description=None, enabled=True, hf_endpoint='https://huggingface.co', model_uri='hf://nvidia/Llama-3_3-Nemotron-Super-49B-v1_5', name='nemotron-super-llama-3.3-49b@1.5', namespace='nvidia', ownership=None, project=None, status='ready', tokenizer=None, updated_at=datetime.datetime(2025, 10, 22, 13, 58, 47, 766241), schema_version='1.0', model_type='hf'), training_precision='bf16-mixed', updated_at=datetime.datetime(2025, 10, 22, 13, 58, 37, 572277))\n"
     ]
    }
   ],
   "source": [
    "# Get customization config details\n",
    "cust_config =nemo_client.customization.configs.retrieve(\n",
    "    config_name=\"nemotron-super-llama-3.3-49b@v1.5+A100\",\n",
    "    namespace=\"nvidia\"\n",
    ")\n",
    "print(cust_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcdfe567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job with W&B integration:\n",
      "Job ID: cust-ULHUmRxu6kW8YekzzufuFv\n",
      "Status: created\n"
     ]
    }
   ],
   "source": [
    "# Create a customization job\n",
    "job = nemo_client.customization.jobs.create(\n",
    "    config=\"nvidia/nemotron-super-llama-3.3-49b@v1.5+A100\",\n",
    "    dataset={\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"namespace\": NAMESPACE\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 8\n",
    "        }\n",
    "    },\n",
    "    output_model=\"nvidia/nemotron-super-lora@v1\",\n",
    ")\n",
    "\n",
    "print(f\"Job ID: {job.id}\")\n",
    "print(f\"Status: {job.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2990d169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomizationStatusDetails(created_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), status='running', updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36), detail=None, message='PVCCreated'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36), detail=None, message='EntityHandler_0_Created'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), detail=None, message='created'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), detail='The training job is pending', message='TrainingJobPending'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='EntityHandler_0_Pending'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='EntityHandler_0_Completed'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='TrainingJobCreated'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='TrainingJobPending'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 48), detail=None, message='container in pod cust-ulhumrxu6kw8yekzzufufv-training-job-worker-0 is waiting because ContainerCreating: None'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 34, 7), detail=None, message='TrainingJobRunning')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_client.customization.jobs.status(job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fb94a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# wait for training to complete before moving to inference\n",
    "while True:\n",
    "    status = nemo_client.customization.jobs.status(job.id)\n",
    "    if status.status == \"completed\" or status.status == \"failed\":\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "print(status.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc838003",
   "metadata": {},
   "source": [
    "## Step 4. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4e288e6-1d85-4b0f-92ad-064cd8b27626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDeployment(config=DeploymentConfig(created_at=None, custom_fields=None, description=None, external_endpoint=None, model='nvidia/nemotron-super-llama-3.3-49b-v1.5', name=None, namespace=None, nim_deployment=NIMDeploymentConfig(gpu=4, image_name='nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1.5', image_tag='1.13.1', additional_envs={'NIM_GUIDED_DECODING_BACKEND': 'outlines'}, disable_lora_support=False, namespace=None, pvc_size='200Gi'), ownership=None, project=None, schema_version=None, updated_at=None), status_details=ModelDeploymentStatusDetails(status='pending', description='Model deployment created'), url='', async_enabled=False, created_at=datetime.datetime(2025, 10, 22, 1, 0, 2, 167944, tzinfo=TzInfo(0)), custom_fields=None, deployed=False, description=None, models=None, name='nemotron-super-llama-3.3-49b-v1.5', namespace='nvidia', ownership=None, project=None, schema_version=None, updated_at=None)\n"
     ]
    }
   ],
   "source": [
    "# Deploying base model NIM with Nemo Deployment Management Service\n",
    "deployment = nemo_client.deployment.model_deployments.create(\n",
    "    name=\"nemotron-super-llama-3.3-49b-v1.5\",\n",
    "    namespace=\"nvidia\",\n",
    "    config={\n",
    "        \"model\": \"nvidia/nemotron-super-llama-3.3-49b-v1.5\",\n",
    "        \"nim_deployment\": {\n",
    "            \"image_name\": \"nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
    "            \"image_tag\": \"1.13.1\",\n",
    "            \"pvc_size\": \"200Gi\",\n",
    "            \"gpu\": 4,\n",
    "            \"additional_envs\": {\n",
    "                \"NIM_GUIDED_DECODING_BACKEND\": \"outlines\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61efa283-7ccc-4356-9a67-0653f565bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDeploymentStatusDetails(status='ready', description='deployment \"modeldeployment-nvidia-nemotron-super-llama-3-3-49b-v1-5\" successfully rolled out\\n')\n"
     ]
    }
   ],
   "source": [
    "# Check deployment status (Wait until the deployment status becomes 'ready' before proceeding. deploying larger model takes 10-20 mins)\n",
    "deployment_status = nemo_client.deployment.model_deployments.retrieve(\n",
    "    namespace=deployment.namespace,\n",
    "    deployment_name=deployment.name\n",
    ")\n",
    "print(deployment_status.status_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d374ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvidia/nemotron-super-llama-3.3-49b-v1.5\n",
      "nvidia/nemotron-super-lora@v1\n"
     ]
    }
   ],
   "source": [
    "# list all available NIMs for inference by their IDs\n",
    "available_nims = nemo_client.inference.models.list()\n",
    "for nim in available_nims.data:\n",
    "    print(nim.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "263b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go through the word **\"strawberry\"** step by step to count how many **'r's** are in it.\n",
      "\n",
      "### Step 1: Write out the word clearly\n",
      "**strawberry**\n",
      "\n",
      "### Step 2: Break it down letter by letter\n",
      "**s - t - r - a - w - b - e - r - r - y**\n",
      "\n",
      "### Step 3: Identify and count the 'r's\n",
      "Let's go through each letter and note when we see an **'r'**:\n",
      "\n",
      "- s → not 'r'\n",
      "- t → not 'r'\n",
      "- **r** → 1st 'r'\n",
      "- a → not 'r'\n",
      "- w → not 'r'\n",
      "- b → not 'r'\n",
      "- e → not 'r'\n",
      "- **r** → 2nd 'r'\n",
      "- **r** → 3rd 'r'\n",
      "- y → not 'r'\n",
      "\n",
      "### Final Answer:\n",
      "There are **3 '\n"
     ]
    }
   ],
   "source": [
    "# Inference with base model\n",
    "response = nemo_client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-super-llama-3.3-49b-v1.5\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"/no_think\"}, \n",
    "        {\"role\":\"user\", \"content\":\"How many 'r's are in 'strawberry'?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    "    stream=False\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e5e82e9-8aad-4f20-a7cf-21cd37b3c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many institutional structures that originated in medieval times continue to exist today, often in evolved or adapted forms. These institutions have played significant roles in shaping modern society in areas such as governance, religion, education, law, and social organization. Here are some key examples:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Monarchies**\n",
      "- **Description**: While many medieval monarchies were absolute, some have evolved into constitutional monarchies.\n",
      "- **Examples**:\n",
      "  - United Kingdom (House of Windsor)\n",
      "  - Japan (House of Yamato, one of the oldest continuous hereditary monarchies)\n",
      "  - Sweden, Norway, Denmark, Netherlands, Belgium, and others in Europe\n",
      "  - Saudi Arabia (House of Saud, with roots in the 18th century but with strong traditional authority)\n",
      "- **Modern Role**: Primarily symbolic or ceremonial in most Western countries, but still influential in some others.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **The Catholic Church**\n",
      "- **Description**: The Roman Catholic Church was a dominant institution in\n"
     ]
    }
   ],
   "source": [
    "# Inference with fined-tuned model\n",
    "response = nemo_client.chat.completions.create(\n",
    "    model=job.output_model,\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"/no_think\"}, \n",
    "        {\"role\":\"user\", \"content\":\"What institutional structures still exist from medieval times?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    "    stream=False\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
