{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba95e45e",
   "metadata": {},
   "source": [
    "# Customizing Llama-3.3-Nemotron-Super-49B-v1.5 with Nemo Customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad0729-7f75-464d-95e4-077726af16cc",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to easily fine-tune the Llama-3.3-Nemotron-Super-49B-v1.5 model using NeMo Customizer. It provides a minimal, end-to-end example that highlights how simple and streamlined the customization process is—from setup to fine-tuning and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcafaea-fcb4-45ff-9242-5309bc50796b",
   "metadata": {},
   "source": [
    "## Step 0. Install Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344436f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NGC API Key ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['NGC_API_KEY'] = getpass(\"Enter your NGC API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a6cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Huggingface token ········\n"
     ]
    }
   ],
   "source": [
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = getpass(\"Enter your Huggingface token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3207aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO]\u001b[0m Starting NeMo Microservices deployment...\n",
      "\u001b[1;32m[INFO]\u001b[0m Detailed logs will be written to: /tmp/nemo-deploy.log\n",
      "\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 1/8: Checking prerequisites [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 12%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 2/8: Downloading Helm chart [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 3/8: Starting Minikube [██████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 37%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 4/8: Setting up NGC and Helm [█████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 50%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 5/8: Installing NeMo microservices [███████████████████████████████░░░░░░░░░░░░░░░░░░░] 62%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 6/8: Waiting for pods [█████████████████████████████████████░░░░░░░░░░░░░] 75%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 7/8: Checking pod health [███████████████████████████████████████████░░░░░░░] 87%\n",
      "\u001b[1;32m[INFO]\u001b[0m Step 8/8: Configuring DNS [██████████████████████████████████████████████████] 100%\n",
      "\u001b[1;32m[INFO]\u001b[0m Deployment completed successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x ./deploy-nmp-2510_nemotron.sh\n",
    "./deploy-nmp-2510_nemotron.sh --progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af180650-9837-4d12-9c3a-e64b79d9e33e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /tmp/tmp7ur17iwq\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.0.1)\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (80.9.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.2 wheel-0.45.1\n",
      "/home/ubuntu/.venv/bin/pip\n",
      "Collecting nemo-microservices==1.1.0\n",
      "  Using cached nemo_microservices-1.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting huggingface-hub==0.34.4\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from nemo-microservices==1.1.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (0.28.1)\n",
      "Collecting pydantic<3,>=1.9.0 (from nemo-microservices==1.1.0)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./.venv/lib/python3.12/site-packages (from nemo-microservices==1.1.0) (4.15.0)\n",
      "Collecting filelock (from huggingface-hub==0.34.4)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub==0.34.4)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface-hub==0.34.4) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub==0.34.4) (6.0.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub==0.34.4) (2.32.5)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub==0.34.4)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub==0.34.4)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->nemo-microservices==1.1.0) (3.11)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->nemo-microservices==1.1.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->nemo-microservices==1.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->nemo-microservices==1.1.0) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->nemo-microservices==1.1.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->nemo-microservices==1.1.0)\n",
      "  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->nemo-microservices==1.1.0)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub==0.34.4) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub==0.34.4) (2.5.0)\n",
      "Using cached nemo_microservices-1.1.0-py3-none-any.whl (750 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, pydantic-core, hf-xet, fsspec, filelock, distro, annotated-types, pydantic, huggingface-hub, nemo-microservices\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [nemo-microservices]emo-microservices]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 filelock-3.20.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.34.4 nemo-microservices-1.1.0 pydantic-2.12.3 pydantic-core-2.41.4 tqdm-4.67.1 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source .venv/bin/activate\n",
    "python -m ensurepip --upgrade\n",
    "python -m pip install --upgrade pip setuptools wheel\n",
    "pip install nemo-microservices==1.1.0 huggingface-hub==0.34.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec26957",
   "metadata": {},
   "source": [
    "## Step 1. Initilize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a73ff219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices import NeMoMicroservices\n",
    "\n",
    "# Configure microservice host URLs\n",
    "NEMO_BASE_URL = \"http://nemo.test\"\n",
    "NIM_BASE_URL = \"http://nim.test\"\n",
    "DATA_STORE_BASE_URL = \"http://data-store.test\"\n",
    "\n",
    "# Initialize the client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_BASE_URL,\n",
    "    inference_base_url=NIM_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82cf0f",
   "metadata": {},
   "source": [
    "## Step 2. Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6539fa6f-10b9-4679-b9c9-94de4fca5d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "training.jsonl: 100%|██████████| 633k/633k [00:00<00:00, 66.8MB/s]\n",
      "validation.jsonl: 100%|██████████| 77.5k/77.5k [00:00<00:00, 10.9MB/s]\n",
      "testing.jsonl: 100%|██████████| 82.6k/82.6k [00:00<00:00, 16.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload testing/testing.jsonl with huggingface_hub', commit_description='', oid='fe943486843c86e9077f6e6a9049d72d18734779', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, upload_file\n",
    "\n",
    "# Define entity details\n",
    "NAMESPACE = \"nemotron-tutorial\"\n",
    "DATASET_NAME = \"example-dataset\"\n",
    "\n",
    "# Initialize HF API client\n",
    "hf_api = HfApi(endpoint=f\"{DATA_STORE_BASE_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create dataset repo in datastore\n",
    "repo_id = f\"{NAMESPACE}/{DATASET_NAME}\"\n",
    "hf_api.create_repo(repo_id , repo_type=\"dataset\")\n",
    "\n",
    "# Upload the dataset\n",
    "hf_api.upload_file(\n",
    "      repo_type=\"dataset\",\n",
    "      repo_id=repo_id,\n",
    "      revision=\"main\",\n",
    "      path_or_fileobj=\"./dataset/training.jsonl\",\n",
    "      path_in_repo=\"training/training.jsonl\" \n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "      repo_type=\"dataset\",\n",
    "      repo_id=repo_id,\n",
    "      revision=\"main\",\n",
    "      path_or_fileobj=\"./dataset/validation.jsonl\",\n",
    "      path_in_repo=\"validation/validation.jsonl\" \n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "      repo_type=\"dataset\",\n",
    "      repo_id=repo_id,\n",
    "      revision=\"main\",\n",
    "      path_or_fileobj=\"./dataset/testing.jsonl\",\n",
    "      path_in_repo=\"testing/testing.jsonl\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f837cc2d-5bde-48e0-94a5-82f5acfd6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(files_url='hf://datasets/nemotron-tutorial/example-dataset', id='dataset-GmW7sSZDkaNUjKMAvE9Hqx', created_at=datetime.datetime(2025, 10, 22, 0, 21, 2, 168799), custom_fields={}, description='test dataset', format=None, hf_endpoint=None, limit=None, name='example-dataset', namespace='nemotron-tutorial', project='customizer-tutorial', split=None, updated_at=datetime.datetime(2025, 10, 22, 0, 21, 2, 168802))\n"
     ]
    }
   ],
   "source": [
    "# Register Dataset in NeMo Entity Store\n",
    "response = nemo_client.datasets.create(\n",
    "    name=DATASET_NAME,\n",
    "    namespace=NAMESPACE,\n",
    "    description=\"test dataset\",\n",
    "    files_url=f\"hf://datasets/{NAMESPACE}/{DATASET_NAME}\",\n",
    "    project=\"customizer-tutorial\",\n",
    "    custom_fields={},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a141e34-3d83-4215-bece-d795e9c65dc6",
   "metadata": {},
   "source": [
    "## Step 3. Run Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffc06fbf-161e-4532-9c54-d05c3b6d6bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 configurations\n",
      "Config namespace: nvidia\n",
      "Config name: nemotron-super-llama-3.3-49b@v1.5+A100\n",
      "  Training options: 1\n",
      "    - sft/lora: 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "# Get all customization configurations\n",
    "configs = nemo_client.customization.configs.list()\n",
    "\n",
    "print(f\"Found {len(configs.data)} configurations\")\n",
    "for config in configs.data:\n",
    "    print(f\"Config namespace: {config.namespace}\")\n",
    "    print(f\"Config name: {config.name}\")\n",
    "    print(f\"  Training options: {len(config.training_options)}\")\n",
    "    for option in config.training_options:\n",
    "        print(f\"    - {option.training_type}/{option.finetuning_type}: {option.num_gpus} GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ebba581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your WandB API Key ········\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: set up WANDB key if you have it\n",
    "os.environ['WANDB_API_KEY'] = getpass(\"Enter your WandB API Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2b57d",
   "metadata": {},
   "source": [
    "Create fine tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcdfe567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job with W&B integration:\n",
      "Job ID: cust-ULHUmRxu6kW8YekzzufuFv\n",
      "Status: created\n"
     ]
    }
   ],
   "source": [
    "# Set up WandB API key for enhanced visualization\n",
    "extra_headers = {}\n",
    "if os.getenv('WANDB_API_KEY'):\n",
    "    extra_headers['wandb-api-key'] = os.getenv('WANDB_API_KEY')\n",
    "\n",
    "# Create a customization job with W&B integration\n",
    "job = nemo_client.customization.jobs.create(\n",
    "    config=\"nvidia/nemotron-super-llama-3.3-49b@v1.5+A100\",\n",
    "    dataset={\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"namespace\": NAMESPACE\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 8\n",
    "        }\n",
    "    },\n",
    "    output_model=\"nvidia/nemotron-super-lora@v1\",\n",
    "    extra_headers=extra_headers\n",
    ")\n",
    "\n",
    "print(f\"Created job with W&B integration:\")\n",
    "print(f\"Job ID: {job.id}\")\n",
    "print(f\"Status: {job.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2990d169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomizationStatusDetails(created_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), status='running', updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36), detail=None, message='PVCCreated'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36), detail=None, message='EntityHandler_0_Created'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), detail=None, message='created'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 36, 464597), detail='The training job is pending', message='TrainingJobPending'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='EntityHandler_0_Pending'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='EntityHandler_0_Completed'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='TrainingJobCreated'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 46), detail=None, message='TrainingJobPending'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 25, 48), detail=None, message='container in pod cust-ulhumrxu6kw8yekzzufufv-training-job-worker-0 is waiting because ContainerCreating: None'), StatusLog(updated_at=datetime.datetime(2025, 10, 22, 0, 34, 7), detail=None, message='TrainingJobRunning')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemo_client.customization.jobs.status(job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fb94a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    status = nemo_client.customization.jobs.status(job.id)\n",
    "    if status.status == \"completed\" or status.status == \"failed\":\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "print(status.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4368f0d-600b-47cb-8474-346b1f690db4",
   "metadata": {},
   "source": [
    "wait for training to complete before moving to inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc838003",
   "metadata": {},
   "source": [
    "## Step 4. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4e288e6-1d85-4b0f-92ad-064cd8b27626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDeployment(config=DeploymentConfig(created_at=None, custom_fields=None, description=None, external_endpoint=None, model='nvidia/nemotron-super-llama-3.3-49b-v1.5', name=None, namespace=None, nim_deployment=NIMDeploymentConfig(gpu=4, image_name='nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1.5', image_tag='1.13.1', additional_envs={'NIM_GUIDED_DECODING_BACKEND': 'outlines'}, disable_lora_support=False, namespace=None, pvc_size='200Gi'), ownership=None, project=None, schema_version=None, updated_at=None), status_details=ModelDeploymentStatusDetails(status='pending', description='Model deployment created'), url='', async_enabled=False, created_at=datetime.datetime(2025, 10, 22, 1, 0, 2, 167944, tzinfo=TzInfo(0)), custom_fields=None, deployed=False, description=None, models=None, name='nemotron-super-llama-3.3-49b-v1.5', namespace='nvidia', ownership=None, project=None, schema_version=None, updated_at=None)\n"
     ]
    }
   ],
   "source": [
    "# Deploying base model NIM with Nemo Deployment Management Service\n",
    "deployment = nemo_client.deployment.model_deployments.create(\n",
    "    name=\"nemotron-super-llama-3.3-49b-v1.5\",\n",
    "    namespace=\"nvidia\",\n",
    "    config={\n",
    "        \"model\": \"nvidia/nemotron-super-llama-3.3-49b-v1.5\",\n",
    "        \"nim_deployment\": {\n",
    "            \"image_name\": \"nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n",
    "            \"image_tag\": \"1.13.1\",\n",
    "            \"pvc_size\": \"200Gi\",\n",
    "            \"gpu\": 4,\n",
    "            \"additional_envs\": {\n",
    "                \"NIM_GUIDED_DECODING_BACKEND\": \"outlines\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61efa283-7ccc-4356-9a67-0653f565bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDeploymentStatusDetails(status='ready', description='deployment \"modeldeployment-nvidia-nemotron-super-llama-3-3-49b-v1-5\" successfully rolled out\\n')\n"
     ]
    }
   ],
   "source": [
    "# Using the deployment object from the previous step\n",
    "deployment_status = nemo_client.deployment.model_deployments.retrieve(\n",
    "    namespace=deployment.namespace,\n",
    "    deployment_name=deployment.name\n",
    ")\n",
    "print(deployment_status.status_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4253b4-1326-4daa-b512-8216c21cb831",
   "metadata": {},
   "source": [
    "Wait until the deployment status becomes 'ready' before proceeding. deploying larger model takes 10-20 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d374ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvidia/nemotron-super-llama-3.3-49b-v1.5\n",
      "nvidia/nemotron-super-lora@v1\n"
     ]
    }
   ],
   "source": [
    "# list all available NIMs for inference by their IDs\n",
    "available_nims = nemo_client.inference.models.list()\n",
    "for nim in available_nims.data:\n",
    "    print(nim.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "263b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go through the word **\"strawberry\"** step by step to count how many **'r's** are in it.\n",
      "\n",
      "### Step 1: Write out the word clearly\n",
      "**strawberry**\n",
      "\n",
      "### Step 2: Break it down letter by letter\n",
      "**s - t - r - a - w - b - e - r - r - y**\n",
      "\n",
      "### Step 3: Identify and count the 'r's\n",
      "Let's go through each letter and note when we see an **'r'**:\n",
      "\n",
      "- s → not 'r'\n",
      "- t → not 'r'\n",
      "- **r** → 1st 'r'\n",
      "- a → not 'r'\n",
      "- w → not 'r'\n",
      "- b → not 'r'\n",
      "- e → not 'r'\n",
      "- **r** → 2nd 'r'\n",
      "- **r** → 3rd 'r'\n",
      "- y → not 'r'\n",
      "\n",
      "### Final Answer:\n",
      "There are **3 '\n"
     ]
    }
   ],
   "source": [
    "# Inference with base model\n",
    "response = nemo_client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-super-llama-3.3-49b-v1.5\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"/no_think\"}, \n",
    "        {\"role\":\"user\", \"content\":\"How many 'r's are in 'strawberry'?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    "    stream=False\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e5e82e9-8aad-4f20-a7cf-21cd37b3c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many institutional structures that originated in medieval times continue to exist today, often in evolved or adapted forms. These institutions have played significant roles in shaping modern society in areas such as governance, religion, education, law, and social organization. Here are some key examples:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Monarchies**\n",
      "- **Description**: While many medieval monarchies were absolute, some have evolved into constitutional monarchies.\n",
      "- **Examples**:\n",
      "  - United Kingdom (House of Windsor)\n",
      "  - Japan (House of Yamato, one of the oldest continuous hereditary monarchies)\n",
      "  - Sweden, Norway, Denmark, Netherlands, Belgium, and others in Europe\n",
      "  - Saudi Arabia (House of Saud, with roots in the 18th century but with strong traditional authority)\n",
      "- **Modern Role**: Primarily symbolic or ceremonial in most Western countries, but still influential in some others.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **The Catholic Church**\n",
      "- **Description**: The Roman Catholic Church was a dominant institution in\n"
     ]
    }
   ],
   "source": [
    "# Inference with fined-tuned model\n",
    "response = nemo_client.chat.completions.create(\n",
    "    model=job.output_model,\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"/no_think\"}, \n",
    "        {\"role\":\"user\", \"content\":\"What institutional structures still exist from medieval times?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    "    stream=False\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
